{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are images?\n",
    "\n",
    "The computer reads any image as a range of values between 0 and 255.\n",
    "\n",
    "**For any color image, there are 3 primary channels – Red, green and blue.** \n",
    "\n",
    "A matrix is formed for every primary color and later these matrices combine to provide a Pixel value for the individual R, G, B colors.\n",
    "\n",
    "<img src= \"./rgb_image.png\">\n",
    "\n",
    "**Note: For a black-white image, there is only one single channel.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is OpenCV?\n",
    "\n",
    "OpenCV is a Python library which is designed to solve computer vision problems. OpenCV was originally developed in 1999 by Intel but later it was supported by Willow Garage.\n",
    "\n",
    "OpenCV supports a wide variety of programming languages such as C++, Python, Java etc. Support for multiple platforms including Windows, Linux, and MacOS.\n",
    "\n",
    "OpenCV used for reading/writing images, object detection, segmentation, image processing, anything to do with images.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install opencv\n",
    "\n",
    "https://pypi.org/project/opencv-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Operations on Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read color Image\n",
    "img = cv2.imread(\"car.jpg\",1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uint8\n",
      "<class 'numpy.ndarray'>\n",
      "(2532, 3798, 3)\n"
     ]
    }
   ],
   "source": [
    "print(img.dtype)\n",
    "print(type(img))\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read grayscale Image\n",
    "img_bw = cv2.imread(\"car.jpg\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "uint8\n",
      "(2532, 3798)\n"
     ]
    }
   ],
   "source": [
    "print(type(img_bw))\n",
    "print(img_bw.dtype)\n",
    "print(img_bw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([104, 104, 104, 103, 103, 104, 103, 104, 105, 105, 105, 103, 101,\n",
       "       100, 102, 103, 105, 105, 105, 105, 106, 108, 103, 103, 103, 103,\n",
       "       103, 103, 103, 103, 104, 104, 103, 102, 101, 101, 100, 100, 101,\n",
       "       100], dtype=uint8)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_bw[1, 50:90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize Image\n",
    "img_resize = cv2.resize(img, (500,500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 500, 3)\n"
     ]
    }
   ],
   "source": [
    "print(img_resize.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is a pixel?\n",
    "\n",
    "All images consist of pixels which are the raw building blocks of images. Images are made of pixels in a grid. Number of pixels = Height of image x Width of image.\n",
    "Each pixel is a tupple, whose dimensions depend on the nature of image.\n",
    "\n",
    "Each pixel in a grayscale image has a value representing the shade of gray. There are 256 shades of gray — from 0 to 255.\n",
    "\n",
    "Pixels in a color image have additional information, color related information.\n",
    "\n",
    "**In OpenCV color images in the RGB (Red, Green, Blue) color space have a 3-tuple associated with each pixel: (B, G, R).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[163 130  37]\n"
     ]
    }
   ],
   "source": [
    "# Reading individual pixels\n",
    "pixel = img[10,10]\n",
    "print(pixel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2532, 3798, 3)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop = img[2000:, 70:170]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(532, 100, 3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crop.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting RGB to Grayscale and Grayscale to B/W image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RGB => Grayscale\n",
    "# Using cv2.imread(image_path, 0/1).\n",
    "# By taking average of the channels.\n",
    "# By using cvtColor funtion. cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Grayscale to B/W\n",
    "# Using threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drawing on Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drawing Rectangle, Circles and Line on an Image. <br>\n",
    "**Note: Drawing operations are inplace, i.e. they affect the orignal image directly.**<br>\n",
    "**Make sure to create a copy first**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drawing a rectangle\n",
    "# cv2.rectangle(image, start_point, end_point, color, thickness)\n",
    "# Color order?\n",
    "# How to fill the rectangle with one color?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drawing circle.\n",
    "# cv2.circle(image, center_coordinates, radius, color, thickness)\n",
    "# Color order?\n",
    "# Fill the circle?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drawing line segment\n",
    "# cv2.line(image, start_point, end_point, color, thickness)\n",
    "\n",
    "# Drawing arrowed line\n",
    "# cv2.arrowedLine(image, start_point, end_point, color, thickness, tipLength)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing text on image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.putText(image, text, org, font, fontScale, color, thickness)\n",
    "# Fonts: FONT_HERSHEY_SIMPLEX, FONT_HERSHEY_PLAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edge detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edge = cv2.Canny(image, minVal, maxVal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Make Track Bar to better understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.createTrackbar('min:', \"edge\", 0, 255, refer)\n",
    "# minv = cv2.getTrackbarPos('min:', \"edge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thresholding images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Simple Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ret, thres = cv2.threshold(source, thresholdValue, maxVal, thresholdingTechnique)\n",
    "# thres = cv2.threshold(gray, 225, 255, cv2.THRESH_BINARY_INV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* cv2.THRESH_BINARY: If pixel intensity is greater than the set threshold, value set to 255, else set to 0 (black).\n",
    "* cv2.THRESH_BINARY_INV: Inverted or Opposite case of cv2.THRESH_BINARY.\n",
    "* cv.THRESH_TRUNC: If pixel intensity value is greater than threshold, it is truncated to the threshold. The pixel values are set to be the same as the threshold. All other values remain the same.\n",
    "* cv.THRESH_TOZERO: Pixel intensity is set to 0, for all the pixels intensity, less than the threshold value.\n",
    "* cv.THRESH_TOZERO_INV: Inverted or Opposite case of cv2.THRESH_TOZERO.\n",
    "\n",
    "Reference: https://www.geeksforgeeks.org/opencv-segmentation-using-thresholding/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Adaptive Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a_thres = cv2.adaptiveThreshold(source, maxVal, adaptiveMethod, thresholdType, blocksize, constant)\n",
    "# adaptive methods:  cv2.ADAPTIVE_THRESH_MEAN_C,  cv2.ADAPTIVE_THRESH_GAUSSIAN_C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Otsu Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ret, thresh1 = cv2.threshold(img, 120, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are filters/kernel?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image Blurring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image Blurring refers to making the image less clear or distinct. It is done with the help of various low pass filters/kernels. <br>\n",
    "Different types of blurring: https://docs.opencv.org/master/d4/d13/tutorial_py_filtering.html<br>\n",
    "https://www.geeksforgeeks.org/python-image-blurring-using-opencv/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image erosion and dilation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For B/W images only. <br>\n",
    "Reference: https://www.geeksforgeeks.org/erosion-dilation-images-using-opencv-python/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
